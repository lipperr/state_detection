{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537edda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "plt.rc('figure', max_open_warning=200)\n",
    "%matplotlib notebook\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "ft_dir_path = pwd + 'features'\n",
    "print(ft_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency bands\n",
    "\n",
    "bands = [(0.9, 4, 'Delta (0.9-4 Hz)', 'D'), (4, 8, 'Theta (4-8 Hz)', 'T'), (8, 14, 'Alpha (8-14 Hz)', 'A'), \n",
    "         (14, 25, 'Beta (14-25 Hz)', 'B'), (25, 40, 'Gamma (25-40 Hz)', 'G')]\n",
    "str_freq = [bands[i][3] for i in range(len(bands))]\n",
    "n_freq = len(str_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localization by scalp regions\n",
    "\n",
    "regions = [(['Fp1','Fp2','Fpz'], 'Fp', 'Pre-frontal'),\n",
    "           (['AF7, AF3','AF4','AF8'], 'AF', 'In-between frontal'),\n",
    "           (['F9','F7','F5','F3','FT9','FT7','FC5','FC3'], 'LF', 'Left Frontal'),\n",
    "           (['F1','Fz','F2','FC1','FCz','FC2'], 'MF', 'Midline Frontal'),\n",
    "           (['F4','F6','F8','F10','FC4','FC6','FT8','FT10'], 'RF', 'Right Frontal'),\n",
    "           (['T7','TP9','TP7'], 'LT', 'Left Temporal'),\n",
    "           (['T8','TP8','TP10'], 'RT', 'Right Temporal'),\n",
    "           (['C5','C3','CP5','CP3'], 'LC', 'Left Central'),\n",
    "           (['C1','Cz','C2','CP1','CPz', 'CP2'], 'MC', 'Midline Central'),\n",
    "           (['C4','C6','CP4','CP6'], 'RC', 'Right Central'),\n",
    "           (['P9','P7','P5','P3'], 'LP', 'Left Parietal'),\n",
    "           (['P1','Pz','P2'], 'MP', 'Midline Parietal'),\n",
    "           (['P4','P6','P8','P10'], 'RP', 'Right Parietal'),\n",
    "           (['PO9','PO7','PO3','O1'], 'LO', 'Left Occipital'),\n",
    "           (['POz','Oz'], 'MO', 'Midline Occipital'),\n",
    "           (['PO4','PO8','PO10','O2'], 'RO', 'Right Occipital')]\n",
    "\n",
    "n_regions = len(regions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2887bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading epochs\n",
    "\n",
    "sec5_epochs = mne.read_epochs(os.path.join(ft_dir_path, 'epochs.fif'))\n",
    "print(sec5_epochs.get_data().shape)\n",
    "\n",
    "sampling_rate = sec5_epochs.info['sfreq']\n",
    "n_samples = sec5_epochs.__len__()\n",
    "n_times = len(sec5_epochs.get_data()[0,0,:])\n",
    "\n",
    "ch_names = sec5_epochs.ch_names\n",
    "n_channels = len(ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6faecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading main features DataFrames\n",
    "\n",
    "df_ft_psd_loc_db = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_psd_loc_db.feather'))\n",
    "df_ft_psd_all_db = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_psd_all_db.feather'))\n",
    "df_ft_psd_ind_loc_log = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_psd_ind_loc_log.feather'))\n",
    "df_ft_psd_ind_all_log = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_psd_ind_all_log.feather'))\n",
    "\n",
    "df_ft_coh = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_coh.feather'))\n",
    "df_ft_plv = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_plv.feather'))\n",
    "df_ft_coh_loc = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_coh_loc.feather'))\n",
    "df_ft_plv_loc = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_plv_loc.feather'))\n",
    "\n",
    "df_ft_coh_ind_loc = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_coh_ind_loc.feather'))\n",
    "df_ft_plv_ind_loc = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_plv_ind_loc.feather'))\n",
    "df_ft_coh_ind_all = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_coh_ind_all.feather'))\n",
    "df_ft_plv_ind_all = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_plv_ind_all.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67134de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features data\n",
    "\n",
    "# PSD & PSD indices\n",
    "ft_psd_loc_db_sc = StandardScaler().fit_transform(df_ft_psd_loc_db.to_numpy())\n",
    "df_ft_psd_loc_db_sc = pd.DataFrame(ft_psd_loc_db_sc, columns=df_ft_psd_loc_db.columns)\n",
    "ft_psd_all_db_sc = StandardScaler().fit_transform(df_ft_psd_all_db.to_numpy())\n",
    "df_ft_psd_all_db_sc = pd.DataFrame(ft_psd_all_db_sc, columns=df_ft_psd_all_db.columns)\n",
    "\n",
    "ft_psd_ind_loc_sc = StandardScaler().fit_transform(df_ft_psd_ind_loc_log.to_numpy())\n",
    "df_ft_psd_ind_loc_sc = pd.DataFrame(ft_psd_ind_loc_sc, columns=df_ft_psd_ind_loc_log.columns)\n",
    "ft_psd_ind_all_sc = StandardScaler().fit_transform(df_ft_psd_ind_all_log.to_numpy())\n",
    "df_ft_psd_ind_all_sc = pd.DataFrame(ft_psd_ind_all_sc, columns=df_ft_psd_ind_all_log.columns)\n",
    "\n",
    "# Coherence indices\n",
    "ft_coh_ind_loc_sc = StandardScaler().fit_transform(df_ft_coh_ind_loc.to_numpy())\n",
    "df_ft_coh_ind_loc_sc = pd.DataFrame(ft_coh_ind_loc_sc, columns=df_ft_coh_ind_loc.columns)\n",
    "\n",
    "# PLV indices\n",
    "ft_plv_ind_loc_sc = StandardScaler().fit_transform(df_ft_plv_ind_loc.to_numpy())\n",
    "df_ft_plv_ind_loc_sc = pd.DataFrame(ft_plv_ind_loc_sc, columns=df_ft_plv_ind_loc.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a715a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting overall PSD, Coherence and PLV with stage bounds\n",
    "\n",
    "ind_rate = '07'\n",
    "\n",
    "# Features DataFrames\n",
    "df_ft_psd = df_ft_psd_all_db\n",
    "df_cols = [col for col in df_ft_coh_ind_all.columns if (ind_rate in col)]\n",
    "df_ft_coh = df_ft_coh_ind_all[df_cols]\n",
    "df_cols = [col for col in df_ft_plv_ind_all.columns if (ind_rate in col)]\n",
    "df_ft_plv = df_ft_plv_ind_all[df_cols]\n",
    "\n",
    "# Initialize plots\n",
    "n_cols = n_freq\n",
    "n_rows = 3\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "plt.subplots_adjust(left=0.02)\n",
    "\n",
    "# PSD plots (1st row)\n",
    "for i in range(n_freq):\n",
    "    y = df_ft_psd.to_numpy()[:,i]  \n",
    "    axs[0,i].plot(y, color='blue')\n",
    "    axs[0,i].set_title(\"PSD \"+ bands[i][2])\n",
    "    axs[0,i].tick_params(axis='both', labelsize=8, direction='in')\n",
    "       \n",
    "# Coherence plots (2nd row)\n",
    "for i in range(n_freq):\n",
    "    y = df_ft_coh.to_numpy()[:,i]\n",
    "    axs[1,i].plot(y, color='blue')\n",
    "    axs[1,i].set_title('Coh_Ind_'+ind_rate+' '+bands[i][2])\n",
    "    axs[1,i].tick_params(axis='both', labelsize=8, direction='in')\n",
    "    \n",
    "# PLV plots (3rd row)\n",
    "for i in range(n_freq):\n",
    "    y = df_ft_plv.to_numpy()[:,i]\n",
    "    axs[2,i].plot(y, color='blue')\n",
    "    axs[2,i].set_title('PLV_Ind_'+ind_rate+' '+bands[i][2])\n",
    "    axs[2,i].tick_params(axis='both', labelsize=8, direction='in')\n",
    "    \n",
    "plt.tight_layout(rect=[0,0.09,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для расчёта оценок качетва кластеризации\n",
    "def cluster_metrics_noground(name, data, labels_pred):\n",
    "    results = [name]\n",
    "    df_data = pd.DataFrame(columns=['Method', 'Silh', 'Cal-Har', 'Dav-Bold'])\n",
    "\n",
    "    # Define the metrics which require only data and predicted labels\n",
    "    cluster_metrics = [\n",
    "        metrics.silhouette_score,\n",
    "        metrics.calinski_harabasz_score,\n",
    "        metrics.davies_bouldin_score\n",
    "    ]\n",
    "\n",
    "    results += [m(data, labels_pred) for m in cluster_metrics]\n",
    "    df_data.loc[0] = results\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cluster_method(data, cl_method, name, df_metrics, **kwargs):\n",
    "    method = cl_method(**kwargs).fit(data)\n",
    "    df = cluster_metrics_noground(name, data, method.labels_)\n",
    "    df_metrics = df_metrics.drop(df_metrics[df_metrics['Method']==name].index, errors='ignore')\n",
    "    df_metrics = pd.concat([df_metrics, df], ignore_index=True)\n",
    "    return method, df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating clustering noground metrics for adjacent pairs of stages (Silh, Cal-Har, Dav-Bold)\n",
    "def calc_stage_metr_noground(df_features, st_edges):\n",
    "    df_metrics = pd.DataFrame(columns=['Method', 'Silh', 'Cal-Har', 'Dav-Bold'])\n",
    "    for _st in range(1, len(st_edges)-1):\n",
    "        name = 'St'+str(_st)+'_St'+str(_st+1)\n",
    "        data = df_features.iloc[st_edges[_st-1]:st_edges[_st+1]].reset_index(drop=True)\n",
    "        labels = [0 for i in range(st_edges[_st]-st_edges[_st-1])] + [1 for i in range(st_edges[_st+1]-st_edges[_st])]\n",
    "        df = cluster_metrics_noground(name, data, labels)\n",
    "        df_metrics = df_metrics.drop(df_metrics[df_metrics['Method']==name].index, errors='ignore')\n",
    "        df_metrics = pd.concat([df_metrics, df], ignore_index=True)\n",
    "    df_metrics.rename(columns={'Method': 'Stages'}, inplace=True)\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc95360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица связности для k соседних по времени эпох\n",
    "# K_NEIGHBORS = 30\n",
    "\n",
    "def knn_con_matr(X):\n",
    "    n_samples = len(X)\n",
    "    sm = sp.sparse.lil_matrix((n_samples, n_samples), dtype=np.int8)\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            if abs(i-j)<=k_neighbours: sm[i,j]=1\n",
    "    return sm.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA decomposition\n",
    "\n",
    "# Number of PCA compnents\n",
    "N_COMP = n_regions\n",
    "\n",
    "df_ft_tot_orig = pd.concat([df_ft_psd_loc_db_sc, df_ft_psd_ind_loc_sc, df_ft_coh_ind_loc_sc, df_ft_plv_ind_loc_sc], axis=1)\n",
    "n_features = len(df_ft_tot_orig.columns)\n",
    "\n",
    "pca = decomposition.PCA(n_components=N_COMP)\n",
    "\n",
    "ft_tot_pca = pca.fit_transform(df_ft_tot_orig)\n",
    "print(ft_tot_pca.shape)\n",
    "print('Explained variance', round(pca.explained_variance_ratio_.sum(), 2))\n",
    "print([round(x,3) for x in pca.explained_variance_ratio_])\n",
    "\n",
    "\n",
    "n_pca_comps = len(ft_tot_pca[0,:])\n",
    "pca_comp_names = ['PCA_'+str(i) for i in range(n_pca_comps)]\n",
    "print(n_pca_comps)\n",
    "print(n_features)\n",
    "print(n_samples)\n",
    "\n",
    "df_ft_tot_pca = pd.DataFrame(ft_tot_pca, columns=pca_comp_names)\n",
    "n_samples = len(df_ft_tot_pca)\n",
    "print(n_samples, df_ft_tot_pca.to_numpy().shape)\n",
    "df_features = df_ft_tot_pca\n",
    "df_features.to_csv('df_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative automatic process of finding best clusterisation \n",
    "\n",
    "# Global variables\n",
    "k_neighb_min = 4 # min distance (time = 4 * duration of epoch)\n",
    "k_neighb_max = 10 # max distance (time = 10 * duration of epoch)\n",
    "n_cl_min = 2 # min number of clusters\n",
    "n_cl_max = 20 # max number of clusters\n",
    "\n",
    "len_st_thr = [25, 30, 35] # stage length thresholds for staging process (* duration of epoch)\n",
    "st_dist_rate = 0.4\n",
    "\n",
    "df_best_metrics = pd.DataFrame(columns=['Method', 'Silh', 'Cal-Har', 'Dav-Bold'])\n",
    "df_st_edges = pd.DataFrame(columns=['Len_min', 'N_clusters', 'K_neighb', 'Silh', 'St_edges'])\n",
    "\n",
    "for n_clusters in range(n_cl_min, n_cl_max+1):\n",
    "    print(n_clusters)\n",
    "    for k_neighbours in range(k_neighb_min, k_neighb_max+1):\n",
    "        # Clustering, Ward method        \n",
    "        cl_name = 'ward_pca_'+str(n_clusters)+'_'+str(k_neighbours)\n",
    "        cl_method, df_best_metrics = apply_cluster_method(data=df_features, cl_method=AgglomerativeClustering, \n",
    "                                                          name=cl_name, df_metrics=df_best_metrics, n_clusters=n_clusters, \n",
    "                                                          linkage='ward', connectivity=knn_con_matr)\n",
    "        # Forming stages from clusters\n",
    "        st_edges = spr.form_stages(cl_method.labels_)\n",
    "        \n",
    "        # Merging stages\n",
    "        for st_len_min in len_st_thr:\n",
    "            st_edges = spr.merge_stages_1st_step(df_features, st_edges, len_threshold=st_len_min) \n",
    "            st_edges = spr.merge_stages_2nd_step(df_features, st_edges, dist_threshold=st_dist_rate) \n",
    "            # Insert clusterization results into DataFrame\n",
    "            silh_metric = df_best_metrics[df_best_metrics['Method']==cl_name].iloc[0]['Silh']\n",
    "            new_row = {'Len_min': st_len_min, 'N_clusters': n_clusters, 'K_neighb': k_neighbours, \n",
    "                                       'Silh': silh_metric, 'St_edges': st_edges}\n",
    "            df_st_edges = pd.concat([df_st_edges, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            # Print results\n",
    "            st_lengths = np.array([st_edges[i+1] - st_edges[i] for i in range(len(st_edges)-1)])\n",
    "\n",
    "display(df_best_metrics)\n",
    "display(df_st_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22648ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_metrics.to_csv('df_best_metrics.csv', index=False)\n",
    "df_st_edges.to_csv('df_st_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering stage edges with different parameters\n",
    " \n",
    "len_st_thr = [25, 30, 35] # stage length thresholds for staging process\n",
    "k_neighb_max_thr = [7, 8, 9, 10] # max distance between epochs to cunstruct array of stage boundaries\n",
    "n_cl_max_thr = [10, 15, 20] # max number of clusters to cunstruct array of stage boundaries\n",
    "\n",
    "cl_center_types = ['med', 'mode', 'mean']\n",
    "n_st_edge_max = 12 # max number of resulting edge clusters ?????\n",
    "\n",
    "df_features = df_ft_tot_pca\n",
    "\n",
    "df_st_edge_metrics = pd.DataFrame(columns=['Method', 'Silh', 'Cal-Har', 'Dav-Bold'])\n",
    "df_stage_metrics = pd.DataFrame(columns=['Method', 'Silh', 'Cal-Har', 'Dav-Bold'])\n",
    "df_st_edges_result = pd.DataFrame(columns=['N_stages', 'St_len_min', 'K_nb_max', 'N_cl_max', 'Cl_cen', \n",
    "                                           'Ward_dist', 'Cen_dist', 'Silh', 'Cal-Har', 'Dav-Bold', 'St_edges'])\n",
    "\n",
    "# Forming general list of stage edges\n",
    "for st_len in len_st_thr:\n",
    "    for k_nb_max in k_neighb_max_thr:\n",
    "        for n_cl in n_cl_max_thr:\n",
    "            # Forming st_edges_all list\n",
    "            st_edges_all = []\n",
    "            st_edges_list = []\n",
    "            st_edges_list += (df_st_edges[(df_st_edges['Len_min']==st_len) & (df_st_edges['K_neighb']<=k_nb_max) &\n",
    "                              (df_st_edges['N_clusters']<=n_cl)]['St_edges'].tolist())\n",
    "\n",
    "            print(st_len, k_nb_max, n_cl)\n",
    "\n",
    "            for _st_edges in st_edges_list:\n",
    "                st_edges_all += _st_edges[1:-1].tolist()\n",
    "            st_edges_all.sort()\n",
    "            df_st_edges_all = pd.DataFrame(st_edges_all)\n",
    "\n",
    "            # Clustering stage edges            \n",
    "\n",
    "            for n_st_edge_clusters in range(2, n_st_edge_max+1):\n",
    "                cl_name = ('kmeans_edges_'+str(n_st_edge_clusters)+'_'+str(st_len)+'_'+str(k_nb_max)+'_'+str(n_cl))\n",
    "                cluster_method, df_st_edge_metrics = apply_cluster_method(data=df_st_edges_all, cl_method=KMeans, \n",
    "                                                                                 name=cl_name, df_metrics=df_st_edge_metrics, \n",
    "                                                                                 n_clusters=n_st_edge_clusters, random_state=0)\n",
    "                # Form stages by centers of clusters (median, mean, mode)\n",
    "                st_clusters = []\n",
    "                st_medians = []\n",
    "                st_modes = []\n",
    "                st_means = []\n",
    "\n",
    "                for _st in range(n_st_edge_clusters):\n",
    "                    st_clusters.append([st_edges_all[i] for i in np.where(cluster_method.labels_ == _st)[0]])\n",
    "\n",
    "                    st_medians.append(int(np.median(st_clusters[_st])))\n",
    "                    mode, count = sp.stats.mode(st_clusters[_st])\n",
    "                    st_modes.append(mode[0])\n",
    "                    st_means.append(int(np.mean(st_clusters[_st])))\n",
    "\n",
    "                st_edges_centers = []\n",
    "                st_dist_w_avg = np.empty(len(cl_center_types))\n",
    "                st_dist_c_avg = np.empty(len(cl_center_types))\n",
    "                \n",
    "                for _cen in range(len(cl_center_types)):\n",
    "                    if (cl_center_types[_cen] == 'med'):\n",
    "                        st_edges_centers.append([0] + sorted(st_medians) + [n_samples])\n",
    "                    if (cl_center_types[_cen] == 'mode'):\n",
    "                        st_edges_centers.append([0] + sorted(st_modes) + [n_samples])\n",
    "                    if (cl_center_types[_cen] == 'mean'):\n",
    "                        st_edges_centers.append([0] + sorted(st_means) + [n_samples])\n",
    "                    # Calculating stage distance\n",
    "                    st_dist_ward, st_dist_centr = spr.calc_stage_distances(df_features, st_edges_centers[_cen])\n",
    "                    st_dist_w_avg[_cen] = np.mean(st_dist_ward)\n",
    "                    st_dist_c_avg[_cen] = np.mean(st_dist_centr)\n",
    "\n",
    "                    # Form resulting stage edges array\n",
    "                    cl_cen = cl_center_types[_cen]\n",
    "\n",
    "                    # Calculating clustering metrics for stages\n",
    "                    st_bands, new_labels = spr.form_stage_bands(st_edges_centers[_cen], n_samples)\n",
    "                    n_stages = len(st_bands)\n",
    "\n",
    "                    name = ('stages_'+cl_cen+'_'+str(n_st_edge_clusters+1)+'_'+str(st_len)+'_'+str(k_nb_max)+'_'+str(n_cl))\n",
    "\n",
    "                    # Overall dataset clustering metrics for stages\n",
    "                    df = cluster_metrics_noground(name, df_features, new_labels)\n",
    "                    df_stage_metrics = df_stage_metrics.drop(df_stage_metrics[df_stage_metrics['Method']==name].index, \n",
    "                                                             errors='ignore')\n",
    "                    df_stage_metrics = pd.concat([df_stage_metrics, df], ignore_index=True)\n",
    "\n",
    "                    # Clustering metrics for pairs of adjacent stages                   \n",
    "                    \n",
    "                    df_adj_st_metr = calc_stage_metr_noground(df_features, st_edges_centers[_cen])\n",
    "                    silh = df_adj_st_metr['Silh'].mean()\n",
    "                    cal_har = df_adj_st_metr['Cal-Har'].mean()\n",
    "                    dav_bold = df_adj_st_metr['Dav-Bold'].mean()\n",
    "\n",
    "                    # Insert stage edges into the DataFrame\n",
    "                    new_row = {'N_stages': n_st_edge_clusters+1, 'St_len_min': st_len, 'K_nb_max': k_nb_max, \n",
    "                                'N_cl_max': n_cl, 'Cl_cen': cl_cen, 'Ward_dist': st_dist_w_avg[_cen], \n",
    "                                'Cen_dist': st_dist_c_avg[_cen], 'Silh': silh, 'Cal-Har': cal_har, 'Dav-Bold': dav_bold,\n",
    "                                'St_edges': st_edges_centers[_cen]}\n",
    "                    df_st_edges_result = pd.concat([df_st_edges_result, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_edge_metrics.to_csv('df_st_edge_metrics12.csv', index=False)\n",
    "df_stage_metrics.to_csv('df_stage_metrics12.csv', index=False)\n",
    "df_st_edges_result.to_csv('df_st_edges_result12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749329cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters for each number of stages\n",
    "\n",
    "min_stage_length = 30 # minimum acceptable stage length\n",
    "\n",
    "df_st_edges_best = pd.DataFrame(columns=df_st_edges_result.columns)\n",
    "n_st_edge_max = 12\n",
    "for n_st in range(3,n_st_edge_max+2):\n",
    "    df = df_st_edges_result[(df_st_edges_result['N_stages']==n_st) & (df_st_edges_result['St_len_min']>=min_stage_length)]\n",
    "    silh_max = df['Silh'].max()\n",
    "    new_row = df[df['Silh']==silh_max].iloc[0]\n",
    "    df_st_edges_best = pd.concat([df_st_edges_best, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "display(df_st_edges_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_edges_best.to_csv('df_st_edges_best.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
