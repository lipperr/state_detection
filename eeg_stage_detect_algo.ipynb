{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08bd83bc",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "plt.rc('figure', max_open_warning=200)\n",
    "%matplotlib notebook\n",
    "sns.set_theme()\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95cf3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize path variables for main folders\n",
    "\n",
    "pwd = os.getcwd()\n",
    "    \n",
    "# Path for loading epoch data and features\n",
    "ft_dir_path = pwd + '/features'\n",
    "print(ft_dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dde6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Frequency bands\n",
    "\n",
    "bands = [(0.9, 4, 'Delta (0.9-4 Hz)', 'D'), (4, 8, 'Theta (4-8 Hz)', 'T'), (8, 14, 'Alpha (8-14 Hz)', 'A'), \n",
    "         (14, 25, 'Beta (14-25 Hz)', 'B'), (25, 40, 'Gamma (25-40 Hz)', 'G')]\n",
    "str_freq = [bands[i][3] for i in range(len(bands))]\n",
    "n_freq = len(str_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0348b51",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading epochs (Meditator data)\n",
    "\n",
    "ft_dir_path = '/home/lipperrdino/verenv/features/'\n",
    "sec5_epochs = mne.read_epochs(os.path.join(ft_dir_path, 'epochs.fif'))\n",
    "print(sec5_epochs.get_data().shape)\n",
    "\n",
    "sampling_rate = sec5_epochs.info['sfreq']\n",
    "n_samples = sec5_epochs.__len__()\n",
    "n_times = len(sec5_epochs.get_data()[0,0,:])\n",
    "\n",
    "ch_names = sec5_epochs.ch_names\n",
    "n_channels = len(ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314081a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading main features DataFrames\n",
    "\n",
    "df_ft_psd_all_db = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_psd_all_db.feather'))\n",
    "df_ft_coh_ind_all = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_coh_ind_all.feather'))\n",
    "df_ft_plv_ind_all = pd.read_feather(os.path.join(ft_dir_path, 'df_ft_plv_ind_all.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d021a",
   "metadata": {},
   "source": [
    "# Clusterization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ff2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для расчёта оценок качетва кластеризации\n",
    "def cluster_metrics_noground(name, data, labels_pred):\n",
    "    results = [name]\n",
    "    df_data = pd.DataFrame(columns=['Method', 'Silh', 'Cal-Har', 'Dav-Bold'])\n",
    "\n",
    "    # Define the metrics which require only data and predicted labels\n",
    "    cluster_metrics = [\n",
    "        metrics.silhouette_score,\n",
    "        metrics.calinski_harabasz_score,\n",
    "        metrics.davies_bouldin_score\n",
    "    ]\n",
    "\n",
    "    results += [m(data, labels_pred) for m in cluster_metrics]\n",
    "    df_data.loc[0] = results\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd543a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cluster_method(data, cl_method, name, df_metrics, **kwargs):\n",
    "    method = cl_method(**kwargs).fit(data)\n",
    "    df = cluster_metrics_noground(name, data, method.labels_)\n",
    "    df_metrics = df_metrics.drop(df_metrics[df_metrics['Method']==name].index, errors='ignore')\n",
    "    df_metrics = pd.concat([df_metrics, df], ignore_index=True)\n",
    "    return method, df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating clustering noground metrics for adjacent pairs of stages (Silh, Cal-Har, Dav-Bold)\n",
    "def calc_stage_metr_noground(df_features, st_edges):\n",
    "    df_metrics = pd.DataFrame(columns=['Method', 'Silh', 'Cal-Har', 'Dav-Bold'])\n",
    "    for _st in range(1, len(st_edges)-1):\n",
    "        name = 'St'+str(_st)+'_St'+str(_st+1)\n",
    "        data = df_features.iloc[st_edges[_st-1]:st_edges[_st+1]].reset_index(drop=True)\n",
    "        labels = [0 for i in range(st_edges[_st]-st_edges[_st-1])] + [1 for i in range(st_edges[_st+1]-st_edges[_st])]\n",
    "        df = cluster_metrics_noground(name, data, labels)\n",
    "        df_metrics = df_metrics.drop(df_metrics[df_metrics['Method']==name].index, errors='ignore')\n",
    "        df_metrics = pd.concat([df_metrics, df], ignore_index=True)\n",
    "    df_metrics.rename(columns={'Method': 'Stages'}, inplace=True)\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67fa70b",
   "metadata": {},
   "source": [
    "## Downloading precalculated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2fc602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_edges_best = pd.read_csv('/home/lipperrdino/verenv/notebooks/df_st_edges_best.csv')\n",
    "df_st_edges = pd.read_csv('/home/lipperrdino/verenv/notebooks/df_st_edges.csv')\n",
    "df_features = pd.read_csv('/home/lipperrdino/verenv/notebooks/df_features.csv')\n",
    "df_st_edge_metrics = pd.read_csv('/home/lipperrdino/verenv/notebooks/df_st_edge_metrics12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_edges_best['St_edges'] = df_st_edges_best['St_edges'].map(lambda x: list(map(int, x[1:-1].split(', '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a52c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_edges['St_edges'] = df_st_edges['St_edges'].map(lambda x: list(map(int, x[1:-1].split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c635084",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stages = 6 # expert choise of result number of stages\n",
    "\n",
    "st_len = df_st_edges_best[df_st_edges_best['N_stages']==n_stages]['St_len_min'].iloc[0]\n",
    "k_nb = df_st_edges_best[df_st_edges_best['N_stages']==n_stages]['K_nb_max'].iloc[0]\n",
    "n_cl = df_st_edges_best[df_st_edges_best['N_stages']==n_stages]['N_cl_max'].iloc[0]\n",
    "\n",
    "# Cluster center type\n",
    "cl_center_type = df_st_edges_best[df_st_edges_best['N_stages']==n_stages]['Cl_cen'].iloc[0]\n",
    "print(st_len, k_nb, n_cl, cl_center_type)\n",
    "\n",
    "# Stage boundary epoch numbers\n",
    "st_edges_result = df_st_edges_best[df_st_edges_best['N_stages']==n_stages]['St_edges'].iloc[0]\n",
    "\n",
    "print(st_edges_result)\n",
    "\n",
    "st_edges_all = []\n",
    "st_edges_list = []\n",
    "st_edges_list += (df_st_edges[(df_st_edges['Len_min']==st_len) & (df_st_edges['K_neighb']<=k_nb) &\n",
    "                  (df_st_edges['N_clusters']<=n_cl)]['St_edges'].tolist())\n",
    "for _st_edges in st_edges_list:\n",
    "    st_edges_all += _st_edges[1:-1]\n",
    "st_edges_all = sorted(st_edges_all)\n",
    "df_st_edges_all = pd.DataFrame(st_edges_all)\n",
    "#print(st_edges_all)\n",
    "\n",
    "\n",
    "\n",
    "# Clustering stage edges\n",
    "cl_name = 'kmeans_edges_'+str(n_stages-1)+'_'+str(st_len)+'_'+str(k_nb)\n",
    "cluster_method, df_st_edge_metrics = cq.apply_cluster_method(data=df_st_edges_all, cl_method=KMeans, \n",
    "                                                            name=cl_name, df_metrics=df_st_edge_metrics, \n",
    "                                                            n_clusters=n_stages-1, random_state=0)\n",
    "edg_labels_all = cluster_method.labels_\n",
    "   \n",
    "# Plotting st_edges_all\n",
    "x = st_edges_all\n",
    "y = [0]*len(x)\n",
    "s = [1.5*x.count(x[i]) for i in range(len(x))]\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(x,y, s=s)\n",
    "ax.set(xlabel='Epoches')\n",
    "ax.tick_params(axis='both', labelsize=11, direction='in')\n",
    "fig.suptitle('Stage edges merged for all parameters', fontsize=16)\n",
    "# plt.savefig(subj_dir_name+' Stage edges merged.png')\n",
    "\n",
    "# Plotting clusters    \n",
    "x = st_edges_all\n",
    "y = cluster_method.labels_\n",
    "s = [1.5*x.count(x[i]) for i in range(len(x))]\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(x,y, s=s)\n",
    "ax.set(xlabel='Epoches', ylabel='Clusters')\n",
    "ax.tick_params(axis='both', labelsize=11, direction='in')\n",
    "fig.suptitle('Stage edge clusters', fontsize=16)\n",
    "# plt.savefig(subj_dir_name+' Stage edge clusters.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5be970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find clustering statistic parameters (Main data)\n",
    "\n",
    "df_st_edg_stats = pd.DataFrame(columns=['Cluster name', 'Median', 'Mean', 'Mode', 'Mode probability', 'Standard deviation', \n",
    "                                        'Median 0.95 confidence interval', 'Cluster size'])\n",
    "st_clusters = []\n",
    "print(n_stages)\n",
    "for _st in range(n_stages-1):\n",
    "    st_clusters.append([st_edges_all[i] for i in np.where(cluster_method.labels_ == _st)[0]])\n",
    "    mode, count = sp.stats.mode(st_clusters[_st])\n",
    "    conf_int_median = spr.median_confidence_interval(pd.Series(st_clusters[_st]), cutoff=0.95)\n",
    "    print(conf_int_median)\n",
    "    new_row = {'Cluster name': 'Boundary cluster '+str(_st), 'Median': int(np.median(st_clusters[_st])), 'Mean': int(np.array(st_clusters[_st]).mean()), 'Mode': mode[0], \n",
    "               'Mode probability': count[0]/len(st_clusters[_st]), 'Standard deviation': int(np.array(st_clusters[_st]).std()), \n",
    "               'Median 0.95 confidence interval': str(conf_int_median), 'Cluster size': len(st_clusters[_st])}\n",
    "\n",
    "    df_st_edg_stats = pd.concat([df_st_edg_stats, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "\n",
    "df_st_edg_stats = df_st_edg_stats.sort_values('Median', ignore_index=True)\n",
    "\n",
    "\n",
    "display(df_st_edg_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63894ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main data\n",
    "df_adj_st_metr = calc_stage_metr_noground(df_features, st_edges_result)\n",
    "st_metr_silh = df_adj_st_metr['Silh'].to_numpy()\n",
    "st_metr_calh = df_adj_st_metr['Cal-Har'].to_numpy()\n",
    "st_metr_davb = df_adj_st_metr['Dav-Bold'].to_numpy()\n",
    "\n",
    "st_dist_ward, st_dist_centr = spr.calc_stage_distances(df_features, st_edges_result)\n",
    "df_adj_st_metr['Centr'] = st_dist_centr\n",
    "df_adj_st_metr['Ward'] = st_dist_ward\n",
    "\n",
    "display(df_adj_st_metr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc561c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_plot(df_ft, df_ft_clust, df_ft_clust_stats, st_edges_result, feature_name, axs, row):\n",
    "    df_ft_clust = [df_ft.iloc[smin:(smax+1), :] for (smin, smax, _) in st_bands]\n",
    "    df_ft_clust_stats = [df_ft_clust[_cl].describe() for _cl in range(n_stages)]\n",
    "    for i in range(n_freq):\n",
    "        y = df_ft.to_numpy()[:,i]  \n",
    "        axs[row,i].plot(y, color='blue')\n",
    "        axs[row,i].vlines(x=st_edges_result[1:-1], ymin=np.min(y), ymax=np.max(y), color='black', linewidth=1.8)\n",
    "        axs[row,i].set_title(feature_name + bands[i][2])\n",
    "        axs[row,i].tick_params(axis='both', labelsize=8, direction='in')\n",
    "\n",
    "        # Error bars (statistic plots)\n",
    "        x_st = [(smin + smax)/2 for (smin, smax, _) in st_bands]\n",
    "        y_st = [df_ft_clust_stats[_cl].loc['mean'][i] for _cl in range(n_stages)]\n",
    "        yerr = np.array([df_ft_clust_stats[_cl].loc[['25%','75%']].to_numpy() for _cl in range(n_stages)])[:,:,i].transpose(1,0)\n",
    "        yerr[0,:] = y_st - yerr[0,:]\n",
    "        yerr[1,:] = yerr[1,:] - y_st\n",
    "        \n",
    "        axs[row,i].errorbar(x_st, y_st, np.abs(yerr), capsize=4, linewidth=2.5, color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting overall PSD, Coherence and PLV with stage bounds\n",
    "\n",
    "ind_rate = '07'\n",
    "\n",
    "st_bands, st_labels = spr.form_stage_bands(st_edges_result, n_samples)\n",
    "\n",
    "# Features DataFrames\n",
    "df_ft_psd = df_ft_psd_all_db\n",
    "df_cols = [col for col in df_ft_coh_ind_all.columns if (ind_rate in col)]\n",
    "df_ft_coh = df_ft_coh_ind_all[df_cols]\n",
    "df_cols = [col for col in df_ft_plv_ind_all.columns if (ind_rate in col)]\n",
    "df_ft_plv = df_ft_plv_ind_all[df_cols]\n",
    "\n",
    "# Initialize plots\n",
    "n_cols = n_freq\n",
    "n_rows = 3\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "plt.subplots_adjust(left=0.02)\n",
    "\n",
    "# PSD plots (1st row)\n",
    "df_ft_clust = [df_ft_psd.iloc[smin:(smax+1), :] for (smin, smax, _) in st_bands]\n",
    "df_ft_clust_stats = [df_ft_clust[_cl].describe() for _cl in range(n_stages)]\n",
    "feature_plot(df_ft_psd, df_ft_clust, df_ft_clust_stats, st_edges_result, 'PSD', axs, 0)\n",
    "\n",
    "# Coherence plots (2nd row)\n",
    "df_ft_clust = [df_ft_coh.iloc[smin:(smax+1), :] for (smin, smax, _) in st_bands]\n",
    "df_ft_clust_stats = [df_ft_clust[_cl].describe() for _cl in range(n_stages)]\n",
    "feature_plot(df_ft_coh, df_ft_clust, df_ft_clust_stats, st_edges_result, 'Coh_Ind_', axs, 1)\n",
    "\n",
    "# PLV plots (3rd row)\n",
    "df_ft_clust = [df_ft_plv.iloc[smin:(smax+1), :] for (smin, smax, _) in st_bands]\n",
    "df_ft_clust_stats = [df_ft_clust[_cl].describe() for _cl in range(n_stages)]\n",
    "feature_plot(df_ft_plv, df_ft_clust, df_ft_clust_stats, st_edges_result, 'PLV_Ind_', axs, 2)      \n",
    "    \n",
    "plt.tight_layout(rect=[0,0.09,1,1])\n",
    "\n",
    "#fig.suptitle('PSD in brain regions by spectrum')\n",
    "plt.savefig(f'features_in_stages{n_stages}.png') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098955f7",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84aa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate stage distances & clustering quality metrics\n",
    "\n",
    "# Main data\n",
    "df_adj_st_metr = calc_stage_metr_noground(df_features, st_edges_result)\n",
    "st_metr_silh = df_adj_st_metr['Silh'].to_numpy()\n",
    "st_metr_calh = df_adj_st_metr['Cal-Har'].to_numpy()\n",
    "st_metr_davb = df_adj_st_metr['Dav-Bold'].to_numpy()\n",
    "\n",
    "st_dist_ward, st_dist_centr = spr.calc_stage_distances(df_features, st_edges_result)\n",
    "df_adj_st_metr['Centr'] = st_dist_centr\n",
    "df_adj_st_metr['Ward'] = st_dist_ward\n",
    "\n",
    "st_dist_centr_max = np.max(st_dist_centr)\n",
    "st_dist_ward_max = np.max(st_dist_ward)\n",
    "st_metr_silh_max = np.max(st_metr_silh)\n",
    "st_metr_calh_max = np.max(st_metr_calh)\n",
    "st_metr_davb_max = np.max(st_metr_davb)\n",
    "\n",
    "display(df_adj_st_metr)\n",
    "df_adj_st_metr.to_csv(f'df_adj_st_metr{n_stages}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f1e8b7",
   "metadata": {},
   "source": [
    "## Main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting stages, distances, silh between adjacent\n",
    "\n",
    "# df_features = df_ft_tot_pca\n",
    "st_bands, st_labels = spr.form_stage_bands(st_edges_result, n_samples)\n",
    "n_stages = len(st_bands)\n",
    "\n",
    "# Sorting cluster labels for st_edges_all\n",
    "#edg_labels_all = cluster_method.labels_\n",
    "labels_uq = sorted(set(edg_labels_all), key=list(edg_labels_all).index)\n",
    "edg_labels_sort = []\n",
    "for _cl in range(len(labels_uq)):\n",
    "    edg_labels_sort += [_cl for i in np.where(edg_labels_all == labels_uq[_cl])[0]]\n",
    "\n",
    "# Getting time length of the stages\n",
    "cluster_events = sec5_epochs.events.copy() # for m10 and m3\n",
    "#cluster_events = epochs_filt_rr[:-2].events.copy() # for m8\n",
    "cluster_events[:,2] = st_labels\n",
    "time_bands = []\n",
    "for i in range(n_stages):\n",
    "    cl_samples = np.where(cluster_events[:,2] == i)[0]\n",
    "    time_bands.append((cluster_events[cl_samples[0]][0], cluster_events[cl_samples[-1]][0], st_bands[i][2]))\n",
    "st_time_len = [round((time_bands[i][1]-time_bands[i][0])/sampling_rate) for i in range(n_stages)]\n",
    "print(st_time_len)\n",
    "\n",
    "# Plotting stages\n",
    "pal = plt.get_cmap('Set3')\n",
    "#pal = plt.get_cmap('gist_ncar')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "for _st in range(n_stages):\n",
    "    # Set x & y limits\n",
    "    (ymin, ymax) = (-0.2, 1.1)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlim(0, n_samples)\n",
    "    \n",
    "    # Stages plot\n",
    "    (x_start, x_end, st_name) = st_bands[_st]\n",
    "    x = np.arange(x_start, x_end+1)\n",
    "    y = np.full(len(x), 0)    \n",
    "    event_label = 'N=%d' % (x_end-x_start+1)\n",
    "    ax.add_patch(Rectangle((x_start, -0.05), x_end-x_start, 0.05, edgecolor = 'black', \n",
    "                           #facecolor = pal(_st/(n_stages-1)), fill=True, lw=1)) # for 9 stages\n",
    "                           facecolor = pal(_st/(n_stages)), fill=True, lw=1)) # for 8 stages\n",
    "    \n",
    "    # Vertical lines (stage boundaries)\n",
    "    ax.vlines(x_end, ymin=ymin, ymax=ymax, color='black', linewidth=1) # black lines\n",
    "    #ax.vlines(x_end, ymin=ymin, ymax=ymax, color=pal(_st/(n_stages-1))) # colored lines\n",
    "    \n",
    "    # Background colors\n",
    "    #ax.axvspan(x_start, x_end, alpha=0.3, color=pal(_st/(n_stages-1)))\n",
    "\n",
    "    # Scatter plot\n",
    "    x_sc = [st_edges_all[i] for i in range(len(st_edges_all)) if edg_labels_sort[i]==_st]\n",
    "    y_sc = np.full(len(x_sc), 0.4)\n",
    "    s = [1.5*x_sc.count(x_sc[i]) for i in range(len(x_sc))]\n",
    "    #ax.scatter(x_sc, y_sc, s=s, color=pal(_st/(n_stages-1))) # for 9 stages\n",
    "    ax.scatter(x_sc, y_sc, s=s, color=pal(_st/(n_stages))) # for 8 stages\n",
    "    \n",
    "    # Add text (st_name & st_length in sec)\n",
    "    plt.text((x_start+x_end)/2, -0.12, st_name, fontsize=10, fontweight='bold', horizontalalignment='center')\n",
    "    plt.text((x_start+x_end)/2, 0.02, str(st_time_len[_st])+'s', fontsize=9, fontstyle='italic', horizontalalignment='center')\n",
    "    \n",
    "# Adjacent stage distances (Centroid) & Silh coef \n",
    "x_dist = st_edges_result[1:-1]\n",
    "y_centr = [_dist/st_dist_centr_max for _dist in st_dist_centr]\n",
    "y_silh = [_dist/st_metr_silh_max for _dist in st_metr_silh]\n",
    "#y_calh = [_dist/st_metr_calh_max for _dist in st_metr_calh]\n",
    "y_davb = [_dist/st_metr_davb_max for _dist in st_metr_davb]\n",
    "    \n",
    "ax.plot(x_dist, y_centr, linestyle='--', marker='o', color='green', label='Centroid distance')\n",
    "ax.plot(x_dist, y_silh, linestyle='--', marker='o', color='blue', label='Silhouette score')\n",
    "#ax.plot(x_dist, y_calh, linestyle='--', marker='o', color='orange', label='Cal-Har metric')\n",
    "ax.plot(x_dist, y_davb, linestyle='--', marker='o', color='red', label='Davies-Bouldin score')\n",
    "\n",
    "ax.set(xlabel='Epoches')\n",
    "ax.tick_params(axis='both', labelsize=11, direction='in')\n",
    "plt.savefig('alg6.png')\n",
    "\n",
    "#plt.tight_layout(rect=[-0.01,0.05,1,1])\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "#leg = fig.legend(handles, labels, loc='lower center', ncol=3, fontsize=11, handlelength=4)# , mode='expand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_epochs_yasa = pd.read_csv('yasa_for_plotting.csv').rename(columns={'Unnamed: 0':'epoch'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ee0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "for _st in range(n_stages):\n",
    "    # Set x & y limits\n",
    "    ymin, ymax = -0.1, 1.1\n",
    "    fig.update_layout(yaxis=dict(range=[ymin, ymax]), xaxis=dict(range=[0, n_samples]))\n",
    "    \n",
    "    # Stages plot\n",
    "    x_start, x_end, st_name = st_bands[_st]\n",
    "    print(x_start, x_end, st_name)\n",
    "    x = np.arange(x_start, x_end + 1)\n",
    "    y = np.full(len(x), 0)\n",
    "    event_label = 'N=%d' % (x_end - x_start + 1)\n",
    "    \n",
    "    fig.add_shape(type='rect',\n",
    "                  x0=x_start, y0=-0.05, x1=x_end, y1=0,\n",
    "                  line=dict(color='black', width=1),\n",
    "                  fillcolor='red',\n",
    "                  opacity=1,\n",
    "                  layer='below'\n",
    "                  )\n",
    "    \n",
    "    # Vertical lines (stage boundaries)\n",
    "    fig.add_shape(type='line',\n",
    "                  x0=x_start+5, y0=ymin + 0.05, x1=x_start+5, y1=ymax,\n",
    "                  line=dict(color='red')\n",
    "                  )\n",
    "    \n",
    "    # Background colors\n",
    "    fig.add_shape(type='rect',\n",
    "                  x0=x_start, y0=ymin, x1=x_end, y1=ymax,\n",
    "                  fillcolor='white',\n",
    "                  opacity=0.3,\n",
    "                  layer='below'\n",
    "                  )\n",
    "    \n",
    "    \n",
    "    fig.add_annotation(text=str(st_time_len[_st]//60) + 'm', x=(x_start + x_end) / 2, y=-0.02,\n",
    "                       font=dict(size=12, color='black', family='Balto'),\n",
    "                       showarrow=False, align='center')\n",
    "\n",
    "colors = {'N1':'lightblue',\n",
    "          'N2':'blue',\n",
    "          'N3': 'darkblue',\n",
    "          'W': 'orange',\n",
    "          'R': 'purple'}\n",
    "\n",
    "\n",
    "for t in marked_epochs_yasa['best'].unique():\n",
    "    dfp = marked_epochs_yasa[marked_epochs_yasa['best']==t]\n",
    "    fig.add_traces(go.Bar(x=dfp['epoch']*6, y = dfp['prob'], name=t,\n",
    "                         marker_color=colors[t]))\n",
    "\n",
    "# Set the figure size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "fig.update_layout(xaxis=dict(title='Stages'), yaxis=dict(title='yasa predictions'), showlegend=False)\n",
    "# Show the figure\n",
    "fig.show()\n",
    "fig.write_image('compare_6_9_stages.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting time length of the stages\n",
    "\n",
    "st_names =['Stage '+str(i+1) for i in range(n_stages)]\n",
    "df_st_time_len = pd.DataFrame(columns=['Parameters']+st_names)\n",
    "\n",
    "time_bands = []\n",
    "for i in range(n_stages):\n",
    "    cl_samples = np.where(cluster_events[:,2] == i)[0]\n",
    "    time_bands.append((cluster_events[cl_samples[0]][0], cluster_events[cl_samples[-1]][0], 'St'+str(i+1)))\n",
    "\n",
    "# Start-end time\n",
    "st_param_dict = dict([(st_names[i], (round(time_bands[i][0]/sampling_rate), round(time_bands[i][1]/sampling_rate))) \n",
    "                      for i in range(n_stages)])\n",
    "new_row = {'Parameters': 'Start-end time, sec'}\n",
    "new_row.update(st_param_dict)\n",
    "df_st_time_len = pd.concat([df_st_time_len, pd.DataFrame(new_row)], ignore_index = True)\n",
    "\n",
    "# Time length, sec\n",
    "st_param_dict = dict([(st_names[i], str((time_bands[i][1]-time_bands[i][0])/sampling_rate)) for i in range(n_stages)])\n",
    "new_row = {'Parameters': 'Time length, sec'}\n",
    "new_row.update(st_param_dict)\n",
    "df_st_time_len = pd.concat([df_st_time_len, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "# Number of epochs, sec\n",
    "st_param_dict = dict([(st_names[i], st_bands[i][1]-st_bands[i][0]+1) for i in range(n_stages)])\n",
    "new_row = {'Parameters': 'Number of epochs'}\n",
    "new_row.update(st_param_dict)\n",
    "df_st_time_len = pd.concat([df_st_time_len, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "display(df_st_time_len)    \n",
    "df_st_time_len.to_csv(f'df_st_time_len{n_stages}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with stage distances (by adjacent pairs)\n",
    "\n",
    "# Forming DataFrame with distance values    \n",
    "st_dist_names = ['St'+str(i)+'_St'+str(i+1) for i in range(1, n_stages)]\n",
    "df_st_dist_pairs = pd.DataFrame(columns=['Method'] + st_dist_names)\n",
    "#display(df_st_dist_pairs)\n",
    " \n",
    "# Ward distances\n",
    "st_dist_ward_dict = dict([(st_dist_names[i], st_dist_ward[i]) for i in range(len(st_dist_names))])\n",
    "new_row = {'Method': 'Ward distance'}\n",
    "new_row.update(st_dist_ward_dict)\n",
    "df_st_dist_pairs = pd.concat([df_st_dist_pairs, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "# Centroid distances\n",
    "st_dist_cen_dict = dict([(st_dist_names[i], st_dist_centr[i]) for i in range(len(st_dist_names))])\n",
    "new_row = {'Method': 'Centroid distance'}\n",
    "new_row.update(st_dist_cen_dict)\n",
    "df_st_dist_pairs = pd.concat([df_st_dist_pairs, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "# Silh metrics\n",
    "st_metr_silh_dict = dict([(st_dist_names[i], st_metr_silh[i]) for i in range(len(st_dist_names))])\n",
    "new_row = {'Method': 'Silhouette Coefficient'}\n",
    "new_row.update(st_metr_silh_dict)\n",
    "df_st_dist_pairs = pd.concat([df_st_dist_pairs, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "# Cal-Har metrics\n",
    "st_metr_calh_dict = dict([(st_dist_names[i], st_metr_calh[i]) for i in range(len(st_dist_names))])\n",
    "new_row = {'Method': 'Calinski-Harabasz Index'}\n",
    "new_row.update(st_metr_calh_dict)\n",
    "df_st_dist_pairs = pd.concat([df_st_dist_pairs, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "# Dav-Bold metrics\n",
    "st_metr_davb_dict = dict([(st_dist_names[i], st_metr_davb[i]) for i in range(len(st_dist_names))])\n",
    "new_row = {'Method': 'Davies-Bouldin Index'}\n",
    "new_row.update(st_metr_davb_dict)\n",
    "df_st_dist_pairs = pd.concat([df_st_dist_pairs, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "display(df_st_dist_pairs)\n",
    "df_st_dist_pairs.to_csv(f'df_st_dist_pairs{n_stages}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5396ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with averaged cluster distances & metrics\n",
    "\n",
    "col_names = ['Subject', 'Center type', 'Ward dist', 'Centr dist', 'Silh Stage', 'Cal-Har Stage', 'Dav-Bold Stage', \n",
    "             'Silh Total', 'Cal-Har Total', 'Dav-Bold Total']\n",
    "df_st_dist_total = pd.DataFrame(columns=col_names)\n",
    "\n",
    "new_row = {'Subject': 'pigarev', 'Center type': cl_center_type}\n",
    "n_pair_metr = len(df_st_dist_pairs)\n",
    "n_head_col = len(new_row)\n",
    "n_add_col = len(col_names)-n_head_col-n_pair_metr \n",
    "\n",
    "st_metr_val = [df_st_dist_pairs[df_st_dist_pairs.columns[1:]].iloc[r].mean() for r in range(n_pair_metr)]\n",
    "new_row_add1 = dict([(col_names[r+n_head_col], st_metr_val[r]) for r in range(n_pair_metr)])\n",
    "new_row.update(new_row_add1)\n",
    "\n",
    "df = cluster_metrics_noground('pigarev', df_features, st_labels)\n",
    "new_row_add2 = dict([(col_names[r+n_head_col+n_pair_metr], df[df.columns[r+1]].iloc[0]) for r in range(n_add_col)])\n",
    "new_row.update(new_row_add2)\n",
    "\n",
    "df_st_dist_total = pd.concat([df_st_dist_total, pd.DataFrame(new_row, index=[0])], ignore_index = True)\n",
    "\n",
    "display(df_st_dist_total)\n",
    "df_st_dist_total.to_csv(f'df_st_dist_total{n_stages}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1835e",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(st_edges_result)\n",
    "st_edges_res_samp = sec5_epochs[st_edges_result[:-1]].events[:,0]\n",
    "st_edges_res_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main data\n",
    "np.savetxt(os.path.join(ft_dir_path, f'st_edges_result{n_stages}.txt'), st_edges_result)\n",
    "np.savetxt(os.path.join(ft_dir_path, f'st_edges_res_samp{n_stages}.txt'), st_edges_res_samp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
